* RRN de sürekli geri yükleme vardir. gecmisle iliskisini kaybetmez. ANN de ise gesmisle bir iliski kalmaz.
* Verilerin arka arkasa birbiri ile iliskisi varsa bu Sequence Data'dir.
* RNN de short term memery vardir. Bundan dolayi lstm cikmistir. RNN bir öncekileri unutur yada cok cok kücük katsayilarla birakir bundan dolayi özellikle fazla olan time serieslerde kullanimi sakincalidir.
* RNN en cok NLP de kullanilir.
* Ranishing and exploding bunlari engellemek icin Batch Normalization kullanilir.
* Layerlardan cikislarda normal dagilim olmuyor. Bundan dolayi da bu yöntemi kullaniyoruz.
* LSTM bu iki problem olan short term memory ve vanishing and exploding problemlerini ortadan kaldirmada yardimci olur.
* 
